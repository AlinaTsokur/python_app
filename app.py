import streamlit as st
import re
import pandas as pd
import uuid
from datetime import datetime, time
from supabase import create_client, Client
import math
import base64
import os
import diver_engine
import levels_engine
import altair as alt
import parsing_engine 
# Reloads removed for production cleanliness
from parsing_engine import parse_value_raw, extract, fmt_num, parse_raw_input, calculate_metrics, generate_full_report

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(
    page_title="VANTA Black",
    page_icon="üñ§",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- üîå –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Supabase ---
@st.cache_resource
def init_connection():
    try:
        url = st.secrets["SUPABASE_URL"]
        key = st.secrets["SUPABASE_KEY"]
        return create_client(url, key)
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Supabase: {e}")
        st.stop()

supabase: Client = init_connection()

# --- üé® CSS: PREMIUM DESIGN ---
import styles
styles.apply_styles(st)

# --- ‚öôÔ∏è –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –∏–∑ –ë–î ---
@st.cache_data(ttl=300)
def load_configurations():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –∏ –ø–æ—Ä–æ–≥–∏ –∏–∑ Supabase."""
    config = {}
    try:
        # 1. Asset Coeffs (Column: asset, coeff)
        res_ac = supabase.table('asset_coeffs').select("*").execute()
        config['asset_coeffs'] = {row['asset']: row['coeff'] for row in res_ac.data} if res_ac.data else {}

        # 2. Porog DOI (Column: tf, btc, eth...)
        res_porog = supabase.table('porog_doi').select("*").execute()
        if res_porog.data:
            df = pd.DataFrame(res_porog.data)
            if 'tf' in df.columns:
                df = df.rename(columns={'tf': 'timeframe'})
            config['porog_doi'] = df
        else:
            config['porog_doi'] = pd.DataFrame()

        # 3. TF Params (Column: tf, k_set, k_ctr...)
        res_tf = supabase.table('tf_params').select("*").execute()
        config['tf_params'] = {row['tf']: row for row in res_tf.data} if res_tf.data else {}

        # 4. Liqshare Thresholds
        res_liq = supabase.table('liqshare_thresholds').select("*").eq('name', 'squeeze').execute()
        config['global_squeeze_limit'] = float(res_liq.data[0]['value']) if res_liq.data else 0.3

        return config
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –∏–∑ –ë–î: {e}")
        return {}

# --- üõ† –•–µ–ª–ø–µ—Ä—ã –ü–∞—Ä—Å–∏–Ω–≥–∞ ---
# MOVED TO parsing_engine.py
# (Imports added at top)

# --- üß† –Ø–î–†–û: 1. RAW INPUT PARSING (–ò–°–ü–†–ê–í–õ–ï–ù–û) ---
# MOVED TO parsing_engine.py

# --- üß† –Ø–î–†–û: 2. CALCULATED METRICS ---
# MOVED TO parsing_engine.py

# --- üîÑ –°–õ–ò–Ø–ù–ò–ï –° –ë–î (Merge-on-Parse) ---
def fetch_and_merge_db(batch_data, config):
    """
    1. –ò—â–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å–≤–µ—á–∏ –≤ –ë–î –ø–æ (exchange, symbol, tf, ts).
    2. –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏.
    """
    if not batch_data: return []
    
    # Helper to normalize key for reliable matching
    def get_merge_key(ex, sym, tf, ts):
        # Normalize TS: "2025-12-10T12:00:00" -> "2025-12-10 12:00"
        # Handles various ISO formats and timezone offsets by taking first 16 chars
        clean_ts = str(ts).replace('T', ' ')[:16]
        return (ex, sym, tf, clean_ts)

    # 1. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤
    # –ù—É–∂–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω—ã –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞
    groups = {} # (ex, sym, tf) -> [ts_list]
    for row in batch_data:
        key = (row.get('exchange'), row.get('symbol_clean'), row.get('tf'))
        if key not in groups: groups[key] = []
        groups[key].append(row.get('ts'))
        
    db_map = {} # (ex, sym, tf, ts) -> db_row
    
    # 2. Batch Fetching
    try:
        for (ex, sym, tf), ts_list in groups.items():
            if not ts_list: continue
            min_ts = min(ts_list)
            max_ts = max(ts_list)
            
            # –ó–∞–ø—Ä–æ—Å –∫ –ë–î: exchange + symbol + tf + –¥–∏–∞–ø–∞–∑–æ–Ω –≤—Ä–µ–º–µ–Ω–∏
            res = supabase.table('candles')\
                .select("*")\
                .eq('exchange', ex)\
                .eq('symbol_clean', sym)\
                .eq('tf', tf)\
                .gte('ts', min_ts)\
                .lte('ts', max_ts)\
                .execute()
                
            if res.data:
                for db_row in res.data:
                     # Use normalized key
                    k = get_merge_key(db_row.get('exchange'), db_row.get('symbol_clean'), db_row.get('tf'), db_row.get('ts'))
                    db_map[k] = db_row
                    
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î –¥–ª—è —Å–ª–∏—è–Ω–∏—è: {e}")
        pass 

    # 3. Merging
    merged_batch = []
    for new_row in batch_data:
        # Use normalized key
        k = get_merge_key(new_row.get('exchange'), new_row.get('symbol_clean'), new_row.get('tf'), new_row.get('ts'))
        existing = db_map.get(k)
        
        if existing:
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å–ª–∏—è–Ω–∏—è:
            combined = existing.copy()
            
            for key, val in new_row.items():
                # –û–±–Ω–æ–≤–ª—è–µ–º, –µ—Å–ª–∏ –≤ –±–∞–∑–µ –ø—É—Å—Ç–æ
                existing_val = combined.get(key)
                is_existing_empty = (existing_val is None) or (isinstance(existing_val, (int, float)) and existing_val == 0)
                
                if is_existing_empty:
                    combined[key] = val
            
            merged_batch.append(combined)
        else:
            merged_batch.append(new_row)
            
    return merged_batch

# --- üíæ –ë–î ---
def save_candles_batch(candles_data):
    if not candles_data: return True
    
    # Deep copy to allow modification during retries
    current_data = [c.copy() for c in candles_data]
    
    # Ensure note exists and remove ID to rely on composite key upsert
    for row in current_data:
        if 'note' not in row: row['note'] = ""
        # Remove 'id' to prevent "null value in column id" error during mixed batch upserts
        row.pop('id', None)
            
    # Attempt loop
    attempt = 0
    max_attempts = 20 # Enough for many missing metrics
    dropped_columns = []
    
    while attempt < max_attempts:
        try:
            # Upsert WITHOUT ignore_duplicates to allow UPDATES
            res = supabase.table('candles').upsert(
                current_data, 
                on_conflict='exchange,symbol_clean,tf,ts'
            ).execute()
            
            return True
        except Exception as e:
            err_str = str(e)
            # Detect column error (PGRST204)
            match = re.search(r"Could not find the '(\w+)' column", err_str)
            if match:
                bad_col = match.group(1)
                if bad_col not in dropped_columns:
                    dropped_columns.append(bad_col)
                    # Remove this column from all rows
                    for row in current_data:
                        row.pop(bad_col, None)
                else:
                     # Loop detected?
                     st.error(f"–ó–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ –Ω–∞ –∫–æ–ª–æ–Ω–∫–µ {bad_col}: {e}")
                     return False
                attempt += 1
            else:
                # Other error
                st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")
                return False
                
    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫ —É–¥–∞–ª–µ–Ω–∏—è –ª–∏—à–Ω–∏—Ö –ø–æ–ª–µ–π.")
    return False

def load_candles_db(limit=100, start_date=None, end_date=None, tfs=None):
    try:
        query = supabase.table('candles').select("*").order('ts', desc=True)
        
        if start_date:
            query = query.gte('ts', start_date.isoformat())
        if end_date:
            # End date inclusive (until end of day)
            end_dt = datetime.combine(end_date, time(23, 59, 59))
            query = query.lte('ts', end_dt.isoformat())
            
        if tfs and len(tfs) > 0:
            # Case-insensitive filter hack: add both cases
            tfs_extended = list(set(tfs + [t.upper() for t in tfs] + [t.lower() for t in tfs]))
            query = query.in_('tf', tfs_extended)
            
        res = query.limit(limit).execute()
        return pd.DataFrame(res.data) if res.data else pd.DataFrame()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ë–î: {e}")
        return pd.DataFrame()

def delete_candles_db(ids):
    try:
        supabase.table('candles').delete().in_('id', ids).execute()
        return True
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {e}")
        return False

def update_candle_db(id, changes):
    try:
        supabase.table('candles').update(changes).eq('id', id).execute()
        return True
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
        return False

# --- üìù REPORTING ---
# MOVED fmt_num, generate_full_report TO parsing_engine.py
# (Imports at top)



# --- üìä –õ–û–ì–ò–ö–ê –ö–û–ú–ü–û–ó–ò–¢–ê (COMPOSITE) ---
def generate_composite_report(candles_list):
    """
    –°—á–∏—Ç–∞–µ—Ç –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –ø–æ –æ–±—ä–µ–º—É (Volume) –æ—Ç—á–µ—Ç –¥–ª—è –≥—Ä—É–ø–ø—ã —Å–≤–µ—á–µ–π.
    """
    # –ú–∏–Ω–∏–º—É–º 3 –±–∏—Ä–∂–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
    if not candles_list or len(candles_list) < 3: return None

    # –ü–æ—Ä–æ–≥–∏ (–∫–∞–∫ –≤ Google Sheets)
    THRESH = {
        'CVD': 1.0, 'TR': 0.5, 'TILT': 2.0,
        'DOI': 0.5, 'LIQ_HIGH': 0.30, 'LIQ_LOW': 0.10
    }

    # Tracking missing data for report warning
    missing_data_report = {}

    def get_val(d, key):
        v = d.get(key)
        # Return None if not numeric number (None is preserved)
        if v is None: return None
        return v if (isinstance(v, (int, float)) and not math.isnan(v)) else None

    def sign_char(val, thr):
        if val is None: return '?'
        if abs(val) < thr: return '0'
        return '+' if val > 0 else '-'

    def dispersion(values, thr):
        valid_vals = [v for v in values if v is not None]
        signs = set()
        for v in valid_vals:
            if v > thr: signs.add(1)
            elif v < -thr: signs.add(-1)
        return "—Å–º–µ—à–∞–Ω–Ω—ã–π" if (1 in signs and -1 in signs) else "–æ–∫"

    # 2. –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ (Smart Weighting)
    def weighted(key, metric_name_for_report):
        valid_candles = []
        missing_exchanges = []
        
        for c in candles_list:
            if get_val(c, key) is not None:
                valid_candles.append(c)
            else:
                missing_exchanges.append(c.get('exchange', 'Unknown'))
        
        # Log missing exchanges if any found
        if missing_exchanges:
            missing_data_report[metric_name_for_report] = missing_exchanges

        if not valid_candles: return None
        
        subset_vol = sum(get_val(c, 'volume') for c in valid_candles)
        if subset_vol == 0: return None
        
        return sum(get_val(c, key) * get_val(c, 'volume') for c in valid_candles) / subset_vol

    # 3. –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
    comp = {
        'cvd':  weighted('cvd_pct', 'CVD'),
        'tr':   weighted('dtrades_pct', 'Trades'),
        'tilt': weighted('tilt_pct', 'Tilt'),
        'doi':  weighted('doi_pct', 'Delta OI'),
        'liq':  weighted('liq_share_pct', 'Liquidation'),
        'clv':  weighted('clv_pct', 'CLV'),
        'upper': weighted('upper_tail_pct', 'Upper Tail'),
        'lower': weighted('lower_tail_pct', 'Lower Tail'),
        'body':  weighted('body_pct', 'Body')
    }

    # 4. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è (Safe Evaluation)
    def safe_fmt(val, dec=2):
        return f"{val:.{dec}f}%" if val is not None else "‚Äî"

    if comp['liq'] is not None:
        if comp['liq'] > THRESH['LIQ_HIGH']: liq_eval = '–≤–µ–¥—É—Ç –ª–∏–∫–≤–∏–¥–∞—Ü–∏–∏'
        elif comp['liq'] <= THRESH['LIQ_LOW']: liq_eval = '—Ñ–æ–Ω'
        else: liq_eval = '—É–º–µ—Ä–µ–Ω–Ω–æ'
    else: liq_eval = '‚Äî'

    if comp['tilt'] is not None:
        if comp['tilt'] >= THRESH['TILT']: tilt_int = 'sell —Ç—è–∂–µ–ª–µ–µ'
        elif comp['tilt'] <= -THRESH['TILT']: tilt_int = 'buy —Ç—è–∂–µ–ª–µ–µ'
        else: tilt_int = '–Ω–µ–π—Ç—Ä'
    else: tilt_int = '‚Äî'

    if comp['clv'] is not None:
        if comp['clv'] >= 70: clv_int = '–ø—Ä–∏–Ω—è—Ç–∏–µ —Å–≤–µ—Ä—Ö—É'
        elif comp['clv'] <= 30: clv_int = '–ø—Ä–∏–Ω—è—Ç–∏–µ —Å–Ω–∏–∑—É'
        else: clv_int = '—Å–µ—Ä–µ–¥–∏–Ω–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞'
    else: clv_int = '‚Äî'

    # Liq Tilt Sums
    ll_vals = [get_val(c, 'liq_long') for c in candles_list]
    ls_vals = [get_val(c, 'liq_short') for c in candles_list]
    sum_ll = sum(v for v in ll_vals if v is not None)
    sum_ls = sum(v for v in ls_vals if v is not None)
    
    # Check if we have ANY valid liquidation data
    has_liq_data = any(v is not None for v in ll_vals) or any(v is not None for v in ls_vals)
    
    if has_liq_data:
        liq_tilt = 'Long –¥–æ–º–∏–Ω–∏—Ä—É—é—Ç' if sum_ll > sum_ls else ('Short –¥–æ–º–∏–Ω–∏—Ä—É—é—Ç' if sum_ls > sum_ll else '—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–æ')
    else:
        liq_tilt = '‚Äî'

    disp_cvd = dispersion([get_val(c, 'cvd_pct') for c in candles_list], THRESH['CVD'])
    disp_doi = dispersion([get_val(c, 'doi_pct') for c in candles_list], THRESH['DOI'])

    # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –±–∏—Ä–∂–∞–º
    def fmt_item(c, key, thr):
        val = get_val(c, key)
        if val is None: return f"{c.get('exchange','?')} ‚Äî"
        sign = '(+)' if val > thr else ('(‚àí)' if val < -thr else '(0)')
        return f"{c.get('exchange','?')} {val:.2f}% {sign}"

    per_cvd = "; ".join([fmt_item(c, 'cvd_pct', THRESH['CVD']) for c in candles_list])
    per_tr  = "; ".join([fmt_item(c, 'dtrades_pct', THRESH['TR']) for c in candles_list])
    per_doi = "; ".join([fmt_item(c, 'doi_pct', THRESH['DOI']) for c in candles_list])

    instr = candles_list[0].get('raw_symbol', 'Unknown')

    tf = candles_list[0].get('tf', '-')
    exchanges_str = ", ".join([c.get('exchange','?') for c in candles_list])

    report = f"""–ö–û–ú–ü–û–ó–ò–¢–ù–ê–Ø –°–í–û–î–ö–ê
‚Ä¢ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç/TF: {instr} / {tf} ‚Ä¢ –ë–∏—Ä–∂–∏: {len(candles_list)} ({exchanges_str})

1) CVD (–¥–µ–ª—å—Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –æ–±—ä—ë–º–∞):
   - –ö–æ–º–ø–æ–∑–∏—Ç: {safe_fmt(comp['cvd'])} , –∑–Ω–∞–∫: {sign_char(comp['cvd'], THRESH['CVD'])} [–¥–∏—Å–ø–µ—Ä—Å–∏—è: {disp_cvd}]
   - –ü–æ –±–∏—Ä–∂–∞–º: {per_cvd}
2) Œî –ø–æ —á–∏—Å–ª—É —Å–¥–µ–ª–æ–∫ (Trades):
   - –ö–æ–º–ø–æ–∑–∏—Ç: {safe_fmt(comp['tr'])} , –∑–Ω–∞–∫: {sign_char(comp['tr'], THRESH['TR'])}
   - –ü–æ –±–∏—Ä–∂–∞–º: {per_tr}
3) –ü–µ—Ä–µ–∫–æ—Å —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —Å–¥–µ–ª–∫–∏ (Tilt, sell vs buy):
   - –ö–æ–º–ø–æ–∑–∏—Ç: {safe_fmt(comp['tilt'])} , –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {tilt_int}
4) –õ–∏–∫–≤–∏–¥–∞—Ü–∏–∏:
   - –î–æ–ª—è: {safe_fmt(comp['liq'])} ‚Ä¢ –ü–µ—Ä–µ–∫–æ—Å: {liq_tilt} ‚Ä¢ –û—Ü–µ–Ω–∫–∞: {liq_eval}
5) Open Interest:
   - –ö–æ–º–ø–æ–∑–∏—Ç ŒîOI%: {safe_fmt(comp['doi'])} , –∑–Ω–∞–∫: {sign_char(comp['doi'], THRESH['DOI'])} [–¥–∏—Å–ø–µ—Ä—Å–∏—è: {disp_doi}]
   - –ü–æ –±–∏—Ä–∂–∞–º: {per_doi}

6) –ì–µ–æ–º–µ—Ç—Ä–∏—è —Å–≤–µ—á–∏:
   - CLV: {safe_fmt(comp['clv'])} ({clv_int})
   - –¢–µ–Ω–∏: –≤–µ—Ä—Ö–Ω—è—è {safe_fmt(comp['upper'])} / –Ω–∏–∂–Ω—è—è {safe_fmt(comp['lower'])}
   - –¢–µ–ª–æ: {safe_fmt(comp['body'])}
"""
    # Warning Section Append
    if missing_data_report:
        report += "\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ–ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n"
        for metric, bad_exchanges in missing_data_report.items():
            report += f"‚Ä¢ {metric}: {', '.join(bad_exchanges)} (–∏—Å–∫–ª—é—á–µ–Ω)\n"

    return report

# --- HELPER: CENTRALIZED BATCH PROCESSING (Refactored) ---
def process_raw_text_batch(raw_text):
    """
    Central function to process raw text input (Tab 1 & Tab 3).
    Performs:
    1. Splitting by Exchange
    2. Parsing (parse_raw_input)
    3. Timestamp filtering/forwarding
    4. DB Enrichment (fetch_and_merge_db)
    5. Metric Calculation
    6. X-RAY Generation
    7. Composite Analysis (Grouping & Validation)
    
    Returns:
        batch (list): List of processed candle dictionaries (with metrics and reports).
        orphan_errors (list): List of validation error strings.
    """
    config = load_configurations()
    if not config:
        return [], ["Configuration load failed"]

    # 1. Split & Clean (Synced with batch_parser.py)
    # Split by Timestamp (DD.MM.YYYY HH:MM)
    # Use robust regex from batch_parser to keep TS at start of chunk
    raw_chunks = re.split(r'(?m)^(?=\d{1,2}\.\d{1,2}\.\d{4}\s+\d{1,2}:\d{2})', raw_text)
    raw_chunks = [x.strip() for x in raw_chunks if x.strip()]
    
    merged_groups = {}
    orphan_errors = [] 

    # 2. Iterate & Parse
    for chunk in raw_chunks:
        # Standard parsing (Engine expects TS at start)
        base_data = parse_raw_input(chunk)
    
        # STRICT CHECK: If TS is missing -> Error
        if not base_data.get('ts'):
             # Create error similar to orphan logic
             err = f"‚Ä¢ {base_data.get('exchange', 'Unknown')} {base_data.get('symbol_clean', 'Unknown')} -> CRITICAL: Missing Timestamp/Exchange"
             orphan_errors.append(err) 
             continue # Skip processing for this candle

        # 2d. Grouping for DB Merge
        key = (base_data.get('exchange'), base_data.get('symbol_clean'), base_data.get('tf'), base_data.get('ts'))
        
        if key not in merged_groups:
            merged_groups[key] = base_data
        else:
            existing = merged_groups[key]
            for k, v in base_data.items():
                if v and (k not in existing or not existing[k]):
                    existing[k] = v
    
    local_batch = list(merged_groups.values())
    
    # 3. DB Enrichment
    final_batch_list = fetch_and_merge_db(local_batch, config)
    
    # 4. Metric Calculation & X-RAY
    temp_all_candles = []
    for raw_data in final_batch_list:
        full_data = calculate_metrics(raw_data, config)
        
        has_main = raw_data.get('buy_volume', 0) != 0
        if has_main: 
            full_data['x_ray'] = generate_full_report(full_data)
        else: 
            full_data['x_ray'] = None
        
        temp_all_candles.append(full_data)

    # 5. Composite Analysis (Strict Mode)
    final_save_list = []
    orphan_errors = [] 
    
    def get_comp_key(r):
        ts = str(r.get('ts', '')).replace('T', ' ')[:16]
        sym = str(r.get('symbol_clean', '')).upper()
        tf = str(r.get('tf', '')).upper()
        return (ts, sym, tf)

    comp_groups = {}
    for row in temp_all_candles:
        grp_key = get_comp_key(row)
        if grp_key not in comp_groups: comp_groups[grp_key] = []
        comp_groups[grp_key].append(row)

    # Separate Valid vs Orphans
    valid_groups = []
    orphans_groups = []

    for key, group in comp_groups.items():
        has_binance = any(c['exchange'] == 'Binance' for c in group)
        if has_binance:
            valid_groups.append(group)
        else:
            orphans_groups.append(group)

    # If orphans exist -> BLOCKING ERROR
    if orphans_groups:
        for grp in orphans_groups:
            orphan = grp[0]
            
            # Try to find "Best Match" to explain why it failed
            best_match = None
            min_diff = 3
            
            o_ts = get_comp_key(orphan)[0]
            o_sym = get_comp_key(orphan)[1]
            o_tf = get_comp_key(orphan)[2]

            for v_grp in valid_groups:
                target = next((c for c in v_grp if c['exchange'] == 'Binance'), v_grp[0])
                t_ts = get_comp_key(target)[0]
                t_sym = get_comp_key(target)[1]
                t_tf = get_comp_key(target)[2]
                
                curr_diff = 0
                if o_ts != t_ts: curr_diff += 1
                if o_sym != t_sym: curr_diff += 1
                if o_tf != t_tf: curr_diff += 1
                
                if curr_diff < min_diff:
                    min_diff = curr_diff
                    best_match = target
            
            err_msg = f"‚Ä¢ {orphan.get('exchange')} {o_sym} {o_ts}"
            if best_match:
                reasons = []
                bm_ts = get_comp_key(best_match)[0]
                bm_sym = get_comp_key(best_match)[1]
                bm_tf = get_comp_key(best_match)[2]

                if o_ts != bm_ts: reasons.append(f"–í—Ä–µ–º—è ({o_ts} vs {bm_ts})")
                if o_sym != bm_sym: reasons.append(f"–¢–∏–∫–µ—Ä ({o_sym} vs {bm_sym})")
                if o_tf != bm_tf: reasons.append(f"–¢–§ ({o_tf} vs {bm_tf})")
                
                err_msg += f" -> –ù–µ —Å–æ–≤–ø–∞–ª–æ —Å Binance: {', '.join(reasons)}"
            else:
                err_msg += " -> –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä—ã –Ω–∞ Binance (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)"
            
            orphan_errors.append(err_msg)
            
        # If orphans, we do NOT return valid list? 
        # Tab 1 logic: "st.session_state.processed_batch = []" if orphans exist.
        # We adhere to this strict logic.
        return [], orphan_errors
        
    else:
        # No orphans - process valid groups
        for group in valid_groups:
            target_candle = next((c for c in group if c['exchange'] == 'Binance'), None)
            if not target_candle: target_candle = group[0]

            if target_candle:
                unique_exchanges = set(r['exchange'] for r in group)
                if len(unique_exchanges) >= 3:
                    # COMPOSITE REPORT using ALL group members
                    # Tab 1 passed 'group' NOT 'members' (variable naming)
                    # And likely function expects list of candles.
                    # We need to check generate_composite_report signature.
                    # Previous code: generate_composite_report(group) - only 1 arg?
                    # Let's check.
                    # Assuming it takes list.
                    
                    # Wait, Tab 3 logic had different call?
                    # No, I implemented detailed valid logic from Tab 1.
                    
                    # We pass 'group' to generate_composite_report
                    comp_report = generate_composite_report(group)
                    target_candle['x_ray_composite'] = comp_report # Assign to Composite field
                
                final_save_list.append(target_candle)

    return final_save_list, []

# --- üñ• UI ---
# --- HEADER ---
def get_base64_image(image_path):
    with open(image_path, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()

logo_path = "assets/logo.png"
if os.path.exists(logo_path):
    img_b64 = get_base64_image(logo_path)
    # Flex container to align image and text. 
    # adjust height via max-height or height in css. vanta text is usually h1.
    st.markdown(
        f"""
        <div style="display: flex; align-items: center; gap: 10px;">
            <img src="data:image/png;base64,{img_b64}" style="height: 50px; width: auto;">
            <h1 style="margin: 0; padding: 0; line-height: 1.0;">VANTA</h1>
        </div>
        """, 
        unsafe_allow_html=True
    )
else:
    st.title("üñ§ VANTA")

# --- NAVIGATION LOGIC ---
import importlib
import batch_parser
importlib.reload(batch_parser) # Force reload to apply fixes immediately

# Dynamic Import of Offline modules
from offline import stage1_loader, stage2_features, stage3_bins, stage4_rules, stage5_bins_stats, stage6_mine_stats
importlib.reload(stage1_loader)
importlib.reload(stage2_features)
importlib.reload(stage3_bins)
importlib.reload(stage4_rules)
importlib.reload(stage5_bins_stats)
importlib.reload(stage6_mine_stats)

TABS = ["–û—Ç—á–µ—Ç—ã", "–°–≤–µ—á–∏", "–î–∏–≤–µ—Ä", "–£—Ä–æ–≤–Ω–∏", "–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è", "–û–±—É—á–µ–Ω–∏–µ"]

# 1. Get current tab from URL or Session State
query_params = st.query_params
default_tab = TABS[0]

# Check if 'tab' is in query params
if "tab" in query_params:
    qp_tab = query_params["tab"]
    if qp_tab in TABS:
        default_tab = qp_tab

# 2. Render Navigation (Radio as Tabs)
# Use a callback to update URL immediately on change
def on_tab_change():
    st.query_params["tab"] = st.session_state.nav_radio

selected_tab = st.radio(
    "Navigation", 
    TABS, 
    index=TABS.index(default_tab), 
    key="nav_radio", 
    label_visibility="collapsed",
    horizontal=True,
    on_change=on_tab_change
)

# ... (Previous Tabs Code) ...

def _display_found_rules(symbol, tf, exchange):
    """Display found rules in a nice summary table."""
    import json
    from pathlib import Path
    
    clean_symbol = symbol.replace("/", "").replace(":", "")
    clean_tf = tf.replace("/", "")
    clean_ex = exchange.replace("/", "")
    
    filepath = Path(f"offline/data/{clean_symbol}_{clean_tf}_{clean_ex}_rules.json")
    if not filepath.exists():
        return
    
    with open(filepath, "r") as f:
        data = json.load(f)
    
    rules = data.get("rules", [])
    meta = data.get("meta", {})
    
    if not rules:
        st.info("–ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (edge threshold —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π –¥–ª—è –º–∞–ª–æ–≥–æ N)")
        return
    
    st.divider()
    st.subheader("üìä –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
    
    # Meta info with tooltips
    cols = st.columns(5)
    cols[0].metric(
        "N —Å–µ—Ç–∞–ø–æ–≤", 
        meta.get("N_setups", "?"),
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–µ—Ç–∞–ø–æ–≤, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
    )
    cols[1].metric(
        "–ù–∞–π–¥–µ–Ω–æ –ø—Ä–∞–≤–∏–ª", 
        meta.get("n_rules", len(rules)),
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤, –ø—Ä–æ—à–µ–¥—à–∏—Ö —Ñ–∏–ª—å—Ç—Ä—ã"
    )
    cols[2].metric(
        "Min support", 
        meta.get("min_support_abs", "?"),
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Ç–∞–ø–æ–≤, –≥–¥–µ –¥–æ–ª–∂–µ–Ω –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω"
    )
    cols[3].metric(
        "Min edge", 
        f"{meta.get('min_edge_threshold', 0):.1%}",
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –Ω–∞–¥ –±–∞–∑–æ–≤–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª–∞"
    )
    cols[4].metric(
        "Base P(UP)", 
        f"{meta.get('base_P_UP', 0.5):.1%}",
        help="–ë–∞–∑–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ (% —Å–µ—Ç–∞–ø–æ–≤ —Å y_dir=UP)"
    )
    
    # Rules table
    for i, rule in enumerate(rules):
        pattern_str = " ‚Üí ".join(rule.get("pattern", []))
        direction = "üîª DOWN" if rule.get("edge_down", 0) > rule.get("edge_up", 0) else "üî∫ UP"
        edge = max(rule.get("edge_up", 0), rule.get("edge_down", 0))
        
        with st.expander(f"**–ü—Ä–∞–≤–∏–ª–æ {i+1}** | {direction} | Edge: {edge:.1%} | Support: {rule.get('support', 0)}"):
            st.caption("üîç **–ü–∞—Ç—Ç–µ—Ä–Ω (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤):**")
            st.code(pattern_str, language=None)
            
            st.caption("üìà **–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:**")
            col1, col2, col3 = st.columns(3)
            col1.metric("P(UP)", f"{rule.get('p_up_smooth', 0):.1%}", help="–°–≥–ª–∞–∂–µ–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞")
            col2.metric("P(DOWN)", f"{rule.get('p_down_smooth', 0):.1%}", help="–°–≥–ª–∞–∂–µ–Ω–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–∞–¥–µ–Ω–∏—è")
            col3.metric("Wins", f"{rule.get('wins_up', 0)}/{rule.get('wins_down', 0)}", help="–ü–æ–±–µ–¥ UP / –ü–æ–±–µ–¥ DOWN")
            
            tti = rule.get("tti_probs", {})
            st.caption("‚è±Ô∏è **ETA (–≤—Ä–µ–º—è –¥–æ –∏–º–ø—É–ª—å—Å–∞):**")
            eta_cols = st.columns(3)
            eta_cols[0].metric("NEAR", f"{tti.get('NEAR', 0):.0%}", help="–ò–º–ø—É–ª—å—Å —á–µ—Ä–µ–∑ 0-1 —Å–≤–µ—á—É")
            eta_cols[1].metric("MID", f"{tti.get('MID', 0):.0%}", help="–ò–º–ø—É–ª—å—Å —á–µ—Ä–µ–∑ 2-4 —Å–≤–µ—á–∏")
            eta_cols[2].metric("EARLY", f"{tti.get('EARLY', 0):.0%}", help="–ò–º–ø—É–ª—å—Å —á–µ—Ä–µ–∑ 5+ —Å–≤–µ—á–µ–π")

if selected_tab == "–û–±—É—á–µ–Ω–∏–µ":
    st.header("üèÅ –¶–µ–Ω—Ç—Ä –û–±—É—á–µ–Ω–∏—è –ú–æ–¥–µ–ª–∏ (V2.1)")
    
    col_cfg, col_stat = st.columns([1, 2])
    
    with col_cfg:
        st.subheader("1. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
        tr_symbol = st.selectbox("–¢–∏–∫–µ—Ä", ["ETH", "BTC", "SOL", "BNB"], index=0)
        tr_tf = st.selectbox("–¢–∞–π–º—Ñ—Ä–µ–π–º", ["1D", "4h", "1h", "15m"], index=0)
        tr_exchange = st.text_input("–ë–∏—Ä–∂–∞", "Binance")
        tr_profile = st.selectbox("–ü—Ä–æ—Ñ–∏–ª—å —Ç–æ–∫–µ–Ω–æ–≤", ["STRICT", "SMALLN"], index=1, 
                                   help="STRICT: –ø–æ–ª–Ω—ã–µ –±–∏–Ω—ã (Q1-Q5), SMALLN: —Å–∂–∞—Ç—ã–µ –∑–æ–Ω—ã (LOW/MID/HIGH)")
        
        start_btn = st.button("üöÄ –ó–ê–ü–£–°–¢–ò–¢–¨ –û–ë–£–ß–ï–ù–ò–ï", type="primary", use_container_width=True)
        
    with col_stat:
        st.subheader("2. –ü—Ä–æ–≥—Ä–µ—Å—Å")
        
        if start_btn:
            status = st.status("–ó–∞–ø—É—Å–∫ –∫–æ–Ω–≤–µ–π–µ—Ä–∞...", expanded=True)
            
            # PHASE 1: LOADING
            status.write("üì• –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Offline Pooling)...")
            success1, msg1, count1 = stage1_loader.run_pipeline(tr_symbol, tr_tf, tr_exchange)
            
            if not success1:
                status.update(label="‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ –∑–∞–≥—Ä—É–∑–∫–∏!", state="error")
                st.error(msg1)
            else:
                status.write(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {msg1}")
                
                # PHASE 2: FEATURES
                status.write("üß† –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Simulation)...")
                try:
                    success2, msg2, count2 = stage2_features.run_simulation(tr_symbol, tr_tf, tr_exchange)
                    
                    if not success2:
                        status.update(label="‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!", state="error")
                        st.error(msg2)
                    else:
                         status.write(f"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–æ–∑–¥–∞–Ω—ã: {msg2}")
                         
                         # PHASE 3: BINNING
                         status.write("üìä –®–∞–≥ 3: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ bins (–∫–≤–∞–Ω—Ç–∏–ª–∏)...")
                         try:
                             success3, msg3 = stage3_bins.run_binning(tr_symbol, tr_tf, tr_exchange)
                             
                             if not success3:
                                 status.update(label="‚ùå –û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è bins!", state="error")
                                 st.error(msg3)
                             else:
                                 status.write(f"‚úÖ Bins —Å–æ–∑–¥–∞–Ω—ã: {msg3}")
                                 
                                 # PHASE 4: MINING RULES
                                 status.write("üîç –®–∞–≥ 4: –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (Mining)...")
                                 try:
                                     success4, msg4 = stage4_rules.run_mining(tr_symbol, tr_tf, tr_exchange, profile=tr_profile)
                                     
                                     if not success4:
                                         status.update(label="‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤!", state="error")
                                         st.error(msg4)
                                     else:
                                         status.write(f"‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–∞–π–¥–µ–Ω—ã: {msg4}")
                                         
                                         # PHASE 5: STATS BINS
                                         status.write("üìà –®–∞–≥ 5: STATS –∫–≤–∞–Ω—Ç–∏–ª–∏...")
                                         try:
                                             success5, msg5 = stage5_bins_stats.run_bins_stats(tr_symbol, tr_tf, tr_exchange)
                                             if not success5:
                                                 status.update(label="‚ùå –û—à–∏–±–∫–∞ STATS bins!", state="error")
                                                 st.error(msg5)
                                             else:
                                                 status.write(f"‚úÖ STATS bins: {msg5}")
                                                 
                                                 # PHASE 6: STATS RULES
                                                 status.write("üî¨ –®–∞–≥ 6: STATS –ø—Ä–∞–≤–∏–ª–∞...")
                                                 try:
                                                     success6, msg6 = stage6_mine_stats.run_mine_stats(tr_symbol, tr_tf, tr_exchange)
                                                     if not success6:
                                                         status.update(label="‚ùå –û—à–∏–±–∫–∞ STATS –ø—Ä–∞–≤–∏–ª!", state="error")
                                                         st.error(msg6)
                                                     else:
                                                         status.write(f"‚úÖ STATS –ø—Ä–∞–≤–∏–ª–∞: {msg6}")
                                                         status.update(label="üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!", state="complete")
                                                         st.balloons()
                                                         _display_found_rules(tr_symbol, tr_tf, tr_exchange)
                                                 except Exception as e:
                                                     status.update(label="‚ùå –û—à–∏–±–∫–∞ Stage 6", state="error")
                                                     st.error(str(e))
                                         except Exception as e:
                                             status.update(label="‚ùå –û—à–∏–±–∫–∞ Stage 5", state="error")
                                             st.error(str(e))
                                         
                                 except Exception as e:
                                     status.update(label="‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (Stage 4)", state="error")
                                     st.error(str(e))
                                 
                         except Exception as e:
                             status.update(label="‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (Stage 3)", state="error")
                             st.error(str(e))
                         
                except Exception as e:
                     status.update(label="‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ (Stage 2)", state="error")
                     st.error(str(e))

if selected_tab == "–û—Ç—á–µ—Ç—ã":
    # TAB 1 CONTENT
    input_text = st.text_area("–í—Å—Ç–∞–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–∏", height=150, label_visibility="collapsed", placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å–≤–µ—á–∏ –∑–¥–µ—Å—å...")
    
    # –°–∫—Ä—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏, –±–µ—Ä–µ–º —Ç–µ–∫—É—â–∏–µ
    user_date = datetime.now().date()
    user_time = datetime.now().time()
    
    col_action, col_save, _ = st.columns([1, 4, 20], gap="small")
    
    with col_action:
        process = st.button("üêæ", type="primary")

    # Save button will be rendered into col_save downstream (after processing)

    if process and input_text:
        # --- REFACTORED CALL ---
        final_save_list, orphan_errors = process_raw_text_batch(input_text)
        
        # Save to session (Validation Mode)
        st.session_state.processed_batch = final_save_list
        st.session_state.validation_errors = orphan_errors
        st.rerun()

    if 'validation_errors' in st.session_state and st.session_state.validation_errors:
        st.error("‚õîÔ∏è –û–®–ò–ë–ö–ê –í–ê–õ–ò–î–ê–¶–ò–ò –ö–û–ú–ü–û–ó–ò–¢–ê")
        st.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥—Ä—É–≥–∏—Ö –±–∏—Ä–∂, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Å–æ–≤–ø–∞–ª–∏ —Å Binance. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ.")
        for msg in st.session_state.validation_errors:
            st.code(msg, language="text")
            
    if 'processed_batch' in st.session_state and st.session_state.processed_batch:
        batch = st.session_state.processed_batch
        
        # Deferred Render: Save button in the top column
        # This ensures it captures the FRESH state after "Parse" is clicked
        with col_save:
             if st.button(f"üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å {len(batch)}", type="secondary", key="save_btn_top"):
                if save_candles_batch(batch):
                    st.toast("–£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!", icon="üíæ")
                    st.cache_data.clear()
        
        # Clear logic previously handled inside the big block, now we iterate
        for idx, full_data in enumerate(batch):
            # Prepare Label
            try:
                ts_obj = datetime.fromisoformat(full_data['ts'])
                ts_str = ts_obj.strftime('%d.%m.%Y %H:%M')
            except:
                ts_str = str(full_data.get('ts'))
            
            # Minimalist Header in Expander Label
            warn_icon = " ‚ö†Ô∏è" if full_data.get('missing_fields') else ""
            label = f"{ts_str} ¬∑ {full_data.get('exchange')} ¬∑ {full_data.get('symbol_clean')} ¬∑ {full_data.get('tf')} ¬∑ O {fmt_num(full_data.get('open'))}{warn_icon}"            
            with st.expander(label):
                if full_data.get('missing_fields'):
                    st.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –¥–∞–Ω–Ω—ã–µ: {', '.join(full_data['missing_fields'])}.\n–ó–Ω–∞—á–µ–Ω–∏—è –∑–∞–º–µ–Ω–µ–Ω—ã –Ω–∞ 0, —á—Ç–æ–±—ã —Ä–∞—Å—á–µ—Ç—ã –Ω–µ —É–ø–∞–ª–∏.")
                
                with st.container(height=300):
                    # === DYNAMIC TABS (Option 1) ===
                    if full_data.get('x_ray_composite'):
                        t_xray, t_comp = st.tabs(["X-RAY", "‚ö°Ô∏è COMPOSITE"])
                        with t_xray:
                             if full_data.get('x_ray'): st.code(full_data['x_ray'], language="yaml")
                        with t_comp:
                             st.code(full_data['x_ray_composite'], language="yaml")
                    else:
                        # Standard View
                        if full_data.get('x_ray'):
                             st.code(full_data['x_ray'], language="yaml")

if selected_tab == "–°–≤–µ—á–∏":
    
    # 0. Filters Toolbar
    f1, f2, f3 = st.columns([2, 2, 1])
    
    with f1:
        # TF Multiselect
        all_tfs = ["1m", "5m", "15m", "1h", "4h", "1d", "1w"]
        selected_tfs = st.multiselect("–¢–∞–π–º—Ñ—Ä–µ–π–º—ã", all_tfs, default=[], placeholder="–í—Å–µ TF", label_visibility="collapsed")
        
    with f2:
        # Date Range Picker
        date_range = st.date_input("–ü–µ—Ä–∏–æ–¥", value=[], label_visibility="collapsed")
        start_d, end_d = None, None
        if len(date_range) == 2:
            start_d, end_d = date_range
        elif len(date_range) == 1:
            start_d = date_range[0]
            
    with f3:
        limit_rows = st.number_input("Limit", value=100, min_value=1, step=50, label_visibility="collapsed")

    # 1. Load Data
    df = load_candles_db(limit=limit_rows, start_date=start_d, end_date=end_d, tfs=selected_tfs)

    if not df.empty:
        if 'note' not in df.columns: df['note'] = ""
        df.insert(0, "delete", False)
        # Convert TS
        df['ts'] = pd.to_datetime(df['ts'], errors='coerce')

        # 2. Controls Toolbar (Top)
        # 2. Controls Toolbar (Top)
        c1, c2, c3 = st.columns([0.2, 0.2, 0.6], vertical_alignment="bottom")
        
        # SAVE BUTTON
        with c1:
             if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å", key="btn_save_top", type="primary"):
                 if "db_editor" in st.session_state and "edited_rows" in st.session_state["db_editor"]:
                     changes_map = st.session_state["db_editor"]["edited_rows"]
                     if changes_map:
                         count = 0
                         for idx, changes in changes_map.items():
                             valid_changes = {k: v for k, v in changes.items() if k != 'delete'}
                             if valid_changes:
                                 row_id = df.iloc[idx]['id']
                                 update_candle_db(row_id, valid_changes)
                                 count += 1
                         if count > 0:
                             st.toast(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ {count} —Å–≤–µ—á–µ–π")
                             st.cache_data.clear()
                             st.rerun()
                         else:
                             st.info("–ù–µ—Ç —Å–º—ã—Å–ª–æ–≤—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π.")
                     else:
                         st.info("–ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π.")
        
        # DELETE BUTTON
        with c2:
            if st.button("üóë –£–¥–∞–ª–∏—Ç—å –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–µ", key="btn_del_top", type="secondary"):
                # Find rows where delete=True in session state
                ids_to_del = []
                
                # 1. Check "Select All" state directly
                if st.session_state.get("select_all_del_top"):
                    ids_to_del = df['id'].tolist()
                
                # 2. Check individual checkboxes from Data Editor
                elif "db_editor" in st.session_state and "edited_rows" in st.session_state["db_editor"]:
                    changes_map = st.session_state["db_editor"]["edited_rows"]
                    for idx, changes in changes_map.items():
                         if changes.get("delete") is True:
                             # Ensure idx is valid for current df
                             if idx < len(df):
                                 ids_to_del.append(df.iloc[idx]['id'])

                ids_to_del = list(set(ids_to_del))

                if ids_to_del:
                    if delete_candles_db(ids_to_del):
                        st.toast(f"–£–¥–∞–ª–µ–Ω–æ {len(ids_to_del)} –∑–∞–ø–∏—Å–µ–π!")
                        st.cache_data.clear()
                        st.rerun()
                else:
                    st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –≤—ã–¥–µ–ª–µ–Ω–æ.")

        # SELECT ALL CHECKBOX
        with c3:
             if st.checkbox("–í—ã–¥–µ–ª–∏—Ç—å –≤—Å–µ", key="select_all_del_top"):
                  df['delete'] = True

        visible_cols = ['ts', 'tf', 'x_ray', 'x_ray_composite', 'report_diver', 'note', 'raw_data']
        
        # 4. Data Editor
        edited_df = st.data_editor(
            df,
            key="db_editor",
            column_order=["delete"] + visible_cols,
            use_container_width=True,
            hide_index=True,
            height=800,
            column_config={
                "delete": st.column_config.CheckboxColumn("üóë", default=False, width=30),
                "ts": st.column_config.DatetimeColumn("Time", format="DD.MM.YYYY HH:mm", width="small"),
                "x_ray": st.column_config.TextColumn("X-RAY", width="small"),
                "x_ray_composite": st.column_config.TextColumn("Composite", width="small"),
                "report_diver": st.column_config.TextColumn("Diver", width="small"),
                "note": st.column_config.TextColumn("Note ‚úèÔ∏è", width="small"),
                "raw_data": st.column_config.TextColumn("Raw", width="medium"),
            }
        )
        
    else:
        st.markdown(
            """
            <div style="
                background-color: rgba(100, 181, 246, 0.1); 
                color: #64B5F6;
                padding: 8px 16px; 
                border-radius: 8px; 
                width: fit-content;
                border: 1px solid rgba(100, 181, 246, 0.2);
                margin-bottom: 10px;
            ">
                ‚ÑπÔ∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞.
            </div>
            """, 
            unsafe_allow_html=True
        )
if selected_tab == "–î–∏–≤–µ—Ä":
    # 1. Mode Selection
    mode = st.radio("–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö", ["–í—ã–±—Ä–∞—Ç—å –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö", "–†—É—á–Ω–æ–π –≤–≤–æ–¥"], horizontal=True, label_visibility="collapsed")
    
    selected_metrics = None
    
    if "–†—É—á–Ω–æ–π" in mode:
        raw_text = st.text_area("–í—Å—Ç–∞–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ —Å–≤–µ—á–∏", height=150, label_visibility="collapsed", placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å–≤–µ—á–∏ –∑–¥–µ—Å—å...", key="manual_candle_input")
        
        # Paw Button
        c_paw, _ = st.columns([1, 10])
        with c_paw:
            if st.button("üêæ", key="btn_manual_paw", type="primary"):
                if raw_text:
                    # --- REFACTORED CALL ---
                    # We reuse the same robust function used in Tab 1
                    try:
                        # Use current time as default, similar to Tab 1
                        final_save_list, orphan_errors = process_raw_text_batch(raw_text)
                        
                        if orphan_errors:
                            st.error("\n".join(orphan_errors))
                        
                        if final_save_list:
                            # In Manual Mode we usually expect 1 candle.
                            # We take the first valid Result (which might be a Composite or Single)
                            m = final_save_list[0]
                            st.session_state['manual_diver_candle'] = m
                            st.rerun()
                        elif not orphan_errors:
                            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç.")
                            
                    except Exception as e:
                        st.error(f"–°–∏—Å—Ç–µ–º–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        
        # Display Manual Result (Persisted)
        if st.session_state.get('manual_diver_candle'):
            
            # Split Screen Logic
            # c_left takes 50%, c_right takes 50%
            c_left, c_right = st.columns([1, 1])
            
            # --- LEFT HALF: EXPANDER ---
            with c_left:
                m_data = st.session_state['manual_diver_candle']
                try:
                    ts_obj = datetime.fromisoformat(m_data.get('ts'))
                    ts_str = ts_obj.strftime('%d.%m.%Y %H:%M')
                except:
                    ts_str = str(m_data.get('ts', '')).replace('T', ' ')[:16]
                
                warn_icon = " ‚ö†Ô∏è" if m_data.get('missing_fields') else ""
                label = f"{ts_str} ¬∑ {m_data.get('exchange')} ¬∑ {m_data.get('symbol_clean')} ¬∑ {m_data.get('tf')} ¬∑ O {fmt_num(m_data.get('open'))}{warn_icon}"
                
                with st.expander(label, expanded=False):
                    if m_data.get('missing_fields'):
                         st.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ–ª—è: {', '.join(m_data['missing_fields'])}")
                         
                    # === DYNAMIC TABS (For Manual Mode) ===
                    if m_data.get('x_ray_composite'):
                        t_xray, t_comp = st.tabs(["X-RAY", "‚ö°Ô∏è COMPOSITE"])
                        with t_xray:
                             if m_data.get('x_ray'): st.code(m_data['x_ray'], language="yaml")
                        with t_comp:
                             st.code(m_data['x_ray_composite'], language="yaml")
                    else:
                        if m_data.get('x_ray'):
                             st.code(m_data['x_ray'], language="yaml")

            # --- RIGHT HALF: CONTROLS ---
            with c_right:
                mk_base = "manu_diver"
                
                # Align Zone, Action, Button on one line in this right half
                r1, r2, r3 = st.columns([2, 2, 1.5], gap="small")
                
                with r1:
                    m_zone = st.selectbox(
                        "üìç –ó–æ–Ω–∞", 
                        ["üå™ –í –≤–æ–∑–¥—É—Ö–µ", "üü¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞", "üî¥ –°–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ"],
                        key=f"zone_{mk_base}",
                        label_visibility="collapsed",
                        index=None,
                        placeholder="üìç –ó–æ–Ω–∞"
                    )
                # Check disable condition
                is_air_m = (m_zone == "üå™ –í –≤–æ–∑–¥—É—Ö–µ")
                
                with r2:
                    m_action = st.selectbox(
                        "‚ö°Ô∏è –î–µ–π—Å—Ç–≤–∏–µ", 
                        [
                            "üõ° –£–¥–µ—Ä–∂–∞–Ω–∏–µ",
                            "‚öîÔ∏è –ü—Ä–æ–±–æ–π",
                            "üé£ –õ.–ü—Ä–æ–±–æ–π",
                            "ü™ú –ù–∞ –≥—Ä–∞–Ω–∏—Ü–µ",
                            "üïØ –¢–µ–ª–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ"
                        ],
                        key=f"act_{mk_base}",
                        label_visibility="collapsed",
                        index=None,
                        placeholder="‚ö°Ô∏è –î–µ–π—Å—Ç–≤–∏–µ" if not is_air_m else "‚õîÔ∏è –ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ –≤ –≤–æ–∑–¥—É—Ö–µ",
                        disabled=is_air_m
                    )
                with r3:
                    if st.button("üîÆ –ê–Ω–∞–ª–∏–∑", key=f"btn_{mk_base}", type="primary", use_container_width=True):
                         # Mapping Logic (clean internal codes)
                        z_map = {
                            "üå™ –í –≤–æ–∑–¥—É—Ö–µ": "Air",
                            "üü¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞": "Support",
                            "üî¥ –°–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ": "Resistance"
                        }

                        
                        a_map = {
                            "üõ° –£–¥–µ—Ä–∂–∞–Ω–∏–µ": "AT_EDGE",
                            "‚öîÔ∏è –ü—Ä–æ–±–æ–π": "BREAK",
                            "üé£ –õ.–ü—Ä–æ–±–æ–π": "PROBE",
                            "ü™ú –ù–∞ –≥—Ä–∞–Ω–∏—Ü–µ": "AT_EDGE_BORDERLINE",
                            "üïØ –¢–µ–ª–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ": "AT_EDGE_TAIL"
                        }
                        
                        zone_code = z_map.get(m_zone)
                        action_code = a_map.get(m_action)
                        
                        # Validate (Action is optional if Zone is Air)
                        if not zone_code or (not action_code and zone_code != "Air"):
                            st.toast("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ –ó–æ–Ω—É –∏ –î–µ–π—Å—Ç–≤–∏–µ!", icon="‚ö†Ô∏è")
                        else:
                            # If Air, action_code might be None, logic handles it
                            report = diver_engine.run_expert_analysis(m_data, zone_code, action_code)
                            st.session_state['manual_diver_report'] = report
                            st.rerun()
            
            # --- BOTTOM: REPORT (Full Width) ---
            if st.session_state.get('manual_diver_report'):
                # Report takes the LEFT HALF width to match the expander width?
                # User said: "Left field with report..."
                # Wait: "Left field with report and right... place 3 other forms".
                # This implies the Report should also be in the Left Half?
                # Or maybe user meant the Expander IS the report.
                # "Left field with report [Expander?] and right... place 3 buttons".
                # Where does the RESULT go?
                # Usually results go below.
                # Let's put the result in the Left Half below the expander.
                
                with c_left:
                    st.code(st.session_state['manual_diver_report'], language="text")

    else: # DB Mode
        # Single Row for Filters + Selector
        # Ratio: TF (small), Dates (med), Selector (wide)
        c_tf, c_date, c_sel = st.columns([1, 1.5, 3], gap="small")
        
        with c_tf:
            all_tfs = ["1m", "5m", "15m", "1h", "4h", "1d", "1w"]
            filter_tfs = st.multiselect(
                "TF", 
                all_tfs, 
                default=[], 
                placeholder="TF", 
                label_visibility="collapsed",
                key="diver_db_tf_filter"
            )
            
        with c_date:
            filter_dates = st.date_input(
                "–ü–µ—Ä–∏–æ–¥", 
                value=[], 
                label_visibility="collapsed",
                key="diver_db_date_filter"
            )
        
        # Parse Dates & Load
        d_start, d_end = None, None
        if len(filter_dates) == 2:
            d_start, d_end = filter_dates
        elif len(filter_dates) == 1:
             d_start = filter_dates[0]
             
        db_df = load_candles_db(limit=500, start_date=d_start, end_date=d_end, tfs=filter_tfs)
        

        selected_metrics = None
        
        with c_sel:
            if not db_df.empty:
                # Create label map
                options_map = {}
                for idx, row in db_df.iterrows():
                    try:
                        ts_str = str(row['ts']).replace('T', ' ')[:16]
                        label = f"{ts_str} | {row.get('symbol_clean')} | {row.get('tf')} | O: {row.get('open')}"
                        options_map[label] = row.to_dict()
                    except:
                        continue
                
                sel_label = st.selectbox(
                    "–í—ã–±–µ—Ä–∏—Ç–µ —Å–≤–µ—á—É", 
                    list(options_map.keys()),
                    index=None,
                    placeholder="–í—ã–±–µ—Ä–∏—Ç–µ —Å–≤–µ—á—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞",
                    label_visibility="collapsed"
                )
                
                if sel_label:
                    # 1. Get raw DB data
                    raw_db_metrics = options_map[sel_label]
                    
                    # 2. Restore missing 'tf_sens' from Config (since DB column might be missing)
                    # Use lighter update if possible, but calculate_metrics is safest
                    config = load_configurations() 
                    selected_metrics = calculate_metrics(raw_db_metrics, config)
            else:
                st.markdown(
                    """
                    <div style="
                        background-color: rgba(100, 181, 246, 0.1); 
                        color: #64B5F6;
                        padding: 8px 12px; 
                        border-radius: 4px; 
                        width: fit-content;
                        font-size: 14px;
                        border: 1px solid rgba(100, 181, 246, 0.2);
                    ">
                        ‚ÑπÔ∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö
                    </div>
                    """, 
                    unsafe_allow_html=True
                )

        if selected_metrics:
            # COPY OF MANUAL INPUT LAYOUT
            m_data = selected_metrics
            
            # Split Screen Logic
            d_left, d_right = st.columns([1, 1])
            
            # --- LEFT HALF: EXPANDER + REPORT ---
            with d_left:
                try:
                    ts_obj = datetime.fromisoformat(str(m_data.get('ts')))
                    ts_str = ts_obj.strftime('%d.%m.%Y %H:%M')
                except:
                    ts_str = str(m_data.get('ts', '')).replace('T', ' ')[:16]
                
                # Check missing fields? DB usually has them or not.
                missing_f = m_data.get('missing_fields', [])
                warn_icon = " ‚ö†Ô∏è" if missing_f else ""
                
                label = f"{ts_str} ¬∑ {m_data.get('exchange')} ¬∑ {m_data.get('symbol_clean')} ¬∑ {m_data.get('tf')} ¬∑ O {m_data.get('open')}{warn_icon}"
                
                with st.expander(label, expanded=False):
                    # Tabs logic
                    xray_val = m_data.get('x_ray')
                    comp_val = m_data.get('x_ray_composite')
                    
                    if comp_val:
                        t_xray, t_comp = st.tabs(["X-RAY", "‚ö°Ô∏è COMPOSITE"])
                        with t_xray:
                             if xray_val: st.code(xray_val, language="yaml")
                        with t_comp:
                             st.code(comp_val, language="yaml")
                    else:
                        if xray_val:
                             st.code(xray_val, language="yaml")
                             
                # Show Report below expander
                if st.session_state.get('db_diver_report'):
                    report_txt = st.session_state['db_diver_report']
                    st.code(report_txt, language="text")
                    
                    if st.button("üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç –≤ –ë–î", key="save_diver_db_btn"):
                        c_id = m_data.get('id')
                        if c_id:
                            try:
                                supabase.table('candles').update({
                                    'report_diver': report_txt
                                }).eq('id', c_id).execute()
                                st.toast("–û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ë–î! ‚úÖ", icon="‚úÖ")
                            except Exception as e:
                                st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
                        else:
                            st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω ID —Å–≤–µ—á–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")

            # --- RIGHT HALF: CONTROLS ---
            with d_right:
                mk_base = "db_diver"
                
                # New Layout: [Zone (1.2), Action (1.2), Analyze (0.7), ITB (0.7)]
                r1, r2, r3, r4 = st.columns([1.2, 1.2, 0.7, 0.7], gap="small")
                
                with r1:
                    d_zone = st.selectbox(
                        "üìç –ó–æ–Ω–∞", 
                        ["üå™ –í –≤–æ–∑–¥—É—Ö–µ", "üü¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞", "üî¥ –°–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ"],
                        key=f"zone_{mk_base}",
                        label_visibility="collapsed",
                        index=None,
                        placeholder="üìç –ó–æ–Ω–∞"
                    )
                # Check disable condition
                is_air_d = (d_zone == "üå™ –í –≤–æ–∑–¥—É—Ö–µ")
                
                with r2:
                    d_action = st.selectbox(
                        "‚ö°Ô∏è –î–µ–π—Å—Ç–≤–∏–µ", 
                        [
                            "üõ° –£–¥–µ—Ä–∂–∞–Ω–∏–µ",
                            "‚öîÔ∏è –ü—Ä–æ–±–æ–π",
                            "üé£ –õ.–ü—Ä–æ–±–æ–π",
                            "ü™ú –ù–∞ –≥—Ä–∞–Ω–∏—Ü–µ",
                            "üïØ –¢–µ–ª–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ"
                        ],
                        key=f"act_{mk_base}",
                        label_visibility="collapsed",
                        index=None,
                        placeholder="‚ö°Ô∏è –î–µ–π—Å—Ç–≤–∏–µ" if not is_air_d else "‚õîÔ∏è –ù–µ–¥–æ—Å—Ç—É–ø–Ω–æ –≤ –≤–æ–∑–¥—É—Ö–µ",
                        disabled=is_air_d
                    )
                # Define Maps (Shared Scope)
                z_map = {
                    "üå™ –í –≤–æ–∑–¥—É—Ö–µ": "Air",
                    "üü¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞": "Support",
                    "üî¥ –°–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ": "Resistance"
                }
                
                a_map = {
                    "üõ° –£–¥–µ—Ä–∂–∞–Ω–∏–µ": "AT_EDGE",
                    "‚öîÔ∏è –ü—Ä–æ–±–æ–π": "BREAK",
                    "üé£ –õ.–ü—Ä–æ–±–æ–π": "PROBE",
                    "ü™ú –ù–∞ –≥—Ä–∞–Ω–∏—Ü–µ": "AT_EDGE_BORDERLINE",
                    "üïØ –¢–µ–ª–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ": "AT_EDGE_TAIL"
                }

                with r3:
                    if st.button("üîÆ –ê–Ω–∞–ª–∏–∑", key=f"btn_{mk_base}", type="primary", use_container_width=True):
                        
                        zone_code = z_map.get(d_zone)
                        action_code = a_map.get(d_action)
                        
                        # Validate (Action is optional if Zone is Air)
                        if not zone_code or (not action_code and zone_code != "Air"):
                            st.toast("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ –ó–æ–Ω—É –∏ –î–µ–π—Å—Ç–≤–∏–µ!", icon="‚ö†Ô∏è")
                        else:
                            report = diver_engine.run_expert_analysis(selected_metrics, zone_code, action_code)
                            st.session_state['db_diver_report'] = report
                            st.rerun()

                with r4:
                    if st.button("üõ† –ò–¢–ë", type="secondary", key="btn_toggle_itb", use_container_width=True):
                        st.session_state['show_itb_form'] = not st.session_state.get('show_itb_form', False)

                # --- ITB FORM RENDER ---
                if st.session_state.get('show_itb_form'):
                     itb_ph = f"–í—Å—Ç–∞–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞—Ä–µ–∑–∫–∏ ({str(m_data.get('ts'))})..."
                     itb_text = st.text_area("–î–∞–Ω–Ω—ã–µ –Ω–∞—Ä–µ–∑–∫–∏", height=200, key="itb_input_area", label_visibility="collapsed", placeholder=itb_ph)
                     
                     if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å ITB –ê–Ω–∞–ª–∏–∑", type="primary", key="btn_run_itb_real"):
                            if not itb_text.strip():
                                st.error("–ü—É—Å—Ç–æ–π –≤–≤–æ–¥!")
                            else:
                                slices = []
                                config = load_configurations()
                                lines = itb_text.strip().split('\n')
                                is_valid = True
                                
                                for i, line in enumerate(lines):
                                    if not line.strip(): continue
                                    try:
                                        raw_s = parse_raw_input(line)
                                        met_s = calculate_metrics(raw_s, config)
                                        slices.append(met_s)
                                    except Exception as e:
                                        st.error(f"–û—à–∏–±–∫–∞ –≤ —Å—Ç—Ä–æ–∫–µ {i+1}: {e}")
                                        is_valid = False
                                        break
                                
                                if is_valid:
                                    try:
                                        # Inject Base Analysis
                                        z_code = z_map.get(d_zone)
                                        a_code = a_map.get(d_action)
                                        if z_code and (a_code or z_code == "Air"):
                                            base_cls, base_prob = diver_engine.get_base_analysis(m_data, z_code, a_code)
                                            m_data['cls'] = base_cls
                                            m_data['prob_final'] = base_prob
                                        
                                        res_itb = diver_engine.run_intrabar_analysis(m_data, slices)
                                        st.session_state['itb_result'] = res_itb
                                    except Exception as e:
                                        st.error(f"–û—à–∏–±–∫–∞ –¥–≤–∏–∂–∫–∞ ITB: {e}")
                
                # Show Result Persistent
                if st.session_state.get('itb_result'):
                    st.code(st.session_state['itb_result'], language="text")


# ==============================================================================
# TAB 5: LEVELS (–£–†–û–í–ù–ò)
# ==============================================================================
if selected_tab == "–£—Ä–æ–≤–Ω–∏":
    # 1. Filters (Same as Diver)
    c1, c2, c3 = st.columns([1, 1.5, 3], gap="small")
    
    with c1:
        # TF Multiselect
        all_tfs = ["1h", "4h", "1d", "1w"]
        selected_tfs_lvl = st.multiselect(
            "TF", 
            all_tfs, 
            default=["4h", "1d"], 
            placeholder="TF", 
            label_visibility="collapsed",
            key="levels_tf_filter"
        )
        
    with c2:
        # Date Range
        date_range_lvl = st.date_input(
            "–ü–µ—Ä–∏–æ–¥", 
            value=[], 
            label_visibility="collapsed",
            key="levels_date_filter"
        )
        
    with c3:
        if st.button("üöÄ –†–∞—Å—Å—á–∏—Ç–∞—Ç—å —É—Ä–æ–≤–Ω–∏", type="primary"):
            st.session_state['levels_results'] = {} # Clear stale
            st.session_state['pine_script_dynamic'] = ""
            with st.spinner("–°—á–∏—Ç–∞–µ–º —É—Ä–æ–≤–Ω–∏..."):
                try:
                    if not selected_tfs_lvl:
                        st.error("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–∞–π–º—Ñ—Ä–µ–π–º!")
                    else:
                        d_start, d_end = None, None
                        if len(date_range_lvl) == 2:
                             d_start, d_end = date_range_lvl
                        elif len(date_range_lvl) == 1:
                             d_start = date_range_lvl[0]
                        
                        # Data Collection
                        levels_results = {}
                        candles_data = {} # Store for visualization
                        
                        for tf in selected_tfs_lvl:
                             # Build Query on unified 'candles' table
                             # Handle case-sensitivity (try both '4h' and '4H')
                             query = supabase.table("candles").select("*").in_("tf", [tf.lower(), tf.upper()]).order("ts", desc=True)
                             
                             if d_start:
                                 query = query.gte("ts", d_start.isoformat())
                             if d_end:
                                 # End date + 1 day to cover the full day
                                 d_end_full = d_end + timedelta(days=1)
                                 query = query.lt("ts", d_end_full.isoformat())
                             
                             # Apply limit if no range (Specific Bot Defaults)
                             if not d_start:
                                 if tf == "4h":
                                     limit_val = 180
                                 elif tf == "1d":
                                     limit_val = 365
                                 else:
                                     limit_val = 300
                                 query = query.limit(limit_val)
                             else:
                                 query = query.limit(1000) # Hard limit for range safety

                             res = query.execute()
                             candles = res.data[::-1] if res.data else []
                             
                             if candles:
                                 # Dynamic Max Levels: 1D -> 8, others -> 10
                                 mx = 8 if tf == "1d" else 10
                                 lvls = levels_engine.build_levels(candles, lookback=len(candles), max_levels=mx, timeframe=tf)
                                 # Separate H/L clustering already done inside
                                 
                                 levels_results[tf.upper()] = lvls
                                 candles_data[tf.upper()] = candles # Store for Viz
                        
                        st.session_state['levels_results'] = levels_results
                        st.session_state['candles_data'] = candles_data
                            
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞: {e}")

    # Results
    if st.session_state.get('levels_results'):
        st.divider()
        
        if not any(st.session_state['levels_results'].values()):
             st.warning("‚ö†Ô∏è –£—Ä–æ–≤–Ω–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–≤–µ–ª–∏—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é (Limit) –∏–ª–∏ –≤—ã–±—Ä–∞—Ç—å –¥—Ä—É–≥–æ–π –ø–µ—Ä–∏–æ–¥.")

        # 1. Text Report (Copyable)
        st.subheader("üìã –û—Ç—á–µ—Ç (Copyable)")
        
        report_lines = []
        for tf, lvls in st.session_state['levels_results'].items():
            if not lvls:
                line = f"**{tf} LEVELS:** (–ù–µ—Ç —É—Ä–æ–≤–Ω–µ–π. –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –Ω–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)"
            else:
                # Format: 2945.50 (x2)
                segments = [f"{l['mid']:.2f} (x{l['touches']})" for l in lvls]
                line = f"{tf} LEVELS: " + " / ".join(segments)
            report_lines.append(line)
            
        full_report = "\n\n".join(report_lines)
        st.code(full_report, language="markdown")
        
        # 2. Visualization (Candles + Levels)
        st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (Chart)")
        
        # Tabs for Timeframes
        tf_list = list(st.session_state['levels_results'].keys())
        if tf_list:
            tabs = st.tabs(tf_list)
            
            for i, tf in enumerate(tf_list):
                with tabs[i]:
                    lvls = st.session_state['levels_results'].get(tf, [])
                    c_data = st.session_state.get('candles_data', {}).get(tf, [])
                    
                    if not c_data:
                        st.info("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —Å–≤–µ—á–µ–π –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞.")
                        continue
                        
                    # Prepare DataFrames
                    df_c = pd.DataFrame(c_data)
                    # Ensure numeric and date
                    # Helper to map keys if needed, but Supabase returns dicts matching columns usually
                    # Assuming h, l, c, o, ts/time
                    # Let's clean up column names just in case using extract_val logic or simpler mapping
                    # Assuming standard keys exist
                    
                    # Normalize columns
                    def get_col(row, keys):
                        for k in keys:
                            if k in row: return row[k]
                        return 0
                        
                    df_c['Time'] = pd.to_datetime(df_c['ts']) if 'ts' in df_c.columns else pd.to_datetime(df_c['time'])
                    df_c['Open'] = df_c.apply(lambda x: get_col(x, ['o', 'open']), axis=1)
                    df_c['High'] = df_c.apply(lambda x: get_col(x, ['h', 'high']), axis=1)
                    df_c['Low'] = df_c.apply(lambda x: get_col(x, ['l', 'low']), axis=1)
                    df_c['Close'] = df_c.apply(lambda x: get_col(x, ['c', 'close']), axis=1)
                    
                    # Candle Layer
                    base = alt.Chart(df_c).encode(
                        x=alt.X('Time:T', title=None, axis=alt.Axis(format='%d %b %H:%M'))
                    )
                    
                    rule = base.mark_rule().encode(
                        y=alt.Y('Low:Q', title='Price (USDT)', scale=alt.Scale(zero=False)),
                        y2='High:Q',
                        color=alt.condition("datum.Open <= datum.Close", alt.value("#00C853"), alt.value("#D50000"))
                    )
                    
                    bar = base.mark_bar().encode(
                        y='Open:Q',
                        y2='Close:Q',
                        color=alt.condition("datum.Open <= datum.Close", alt.value("#00C853"), alt.value("#D50000")),
                        tooltip=['Time', 'Open', 'High', 'Low', 'Close']
                    )
                    
                    chart_candles = rule + bar
                    
                    # Levels Layer
                    if lvls:
                        df_req_l = []
                        for l in lvls:
                            df_req_l.append({
                                "Price": l['mid'],
                                "Type": "R" if l['kind'] == 'R' else "S",
                                "Touches": l['touches']
                            })
                        df_l = pd.DataFrame(df_req_l)
                        
                        # Use a dummy base for levels to allow full width rules?
                        # Altair rules without X encoding span the width.
                        # But we need to layer them over time axis.
                        # Actually, if we just use 'y' encoding on a separate data source, it should work as annotation lines.
                        
                        base_l = alt.Chart(df_l).encode(
                            y=alt.Y('Price:Q')
                        )
                        
                        lvl_rules = base_l.mark_rule().encode(
                            color=alt.Color('Type:N', scale=alt.Scale(domain=['S', 'R'], range=['green', 'red']), legend=None),
                            size=alt.Size('Touches:Q', scale=alt.Scale(range=[1, 3]), legend=None),
                            opacity=alt.value(0.7),
                            tooltip=['Type', 'Price', 'Touches']
                        )
                        
                        lvl_text = base_l.mark_text(align='left', dx=2, dy=-5).encode(
                            text=alt.Text('Price', format=".2f"),
                            color=alt.value('white') # Assuming dark mode
                        )
                        
                        final_chart = (chart_candles + lvl_rules + lvl_text).properties(
                            title=f"{tf} Chart with Levels",
                            width='container',
                            height=600
                        ).interactive()
                        
                        st.altair_chart(final_chart, use_container_width=True)
                    else:
                        st.altair_chart(chart_candles.properties(width='container', height=600).interactive(), use_container_width=True)

        
        # Details Expander (Hidden, Debug)
        with st.expander("hidden details (debug)"): 
             # ... existing debug view code if needed
             pass



if selected_tab == "–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è":
    # Text Area
    lab_text = st.text_area("Batch Input", label_visibility="collapsed", height=300, key="lab_text_area", placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å–≤–µ—á–∏ –∏ –º–µ—Ç–∫–∏ (Strong Up/Down)...")
    
    # Action Columns
    col_lab_parse, col_lab_save, col_lab_status = st.columns([1, 3, 7])
    
    with col_lab_parse:
        if st.button("üêæ ", type="primary"):
            if not lab_text.strip():
                st.warning("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç.")
            else:
                # Load config to ensure calculate_metrics works fully
                lab_config = load_configurations()
                st.session_state['lab_segments'], st.session_state['lab_candles'], st.session_state['lab_warnings'] = batch_parser.parse_batch_with_labels(lab_text, config=lab_config)
                st.session_state['lab_checked'] = True
                st.rerun()

    # Results Display
    if st.session_state.get('lab_checked'):
        st.divider()
        warnings = st.session_state.get('lab_warnings', [])
        segments = st.session_state.get('lab_segments', [])
        candles = st.session_state.get('lab_candles', [])
        
        # 1. Warnings (Critical)
        if warnings:
            st.error(f"‚ö†Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–û {len(warnings)} –ü–†–û–ë–õ–ï–ú")
            for w in warnings:
                st.markdown(f"- {w}")
            st.warning("–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π, –∏–Ω–∞—á–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã.")
        
        # 2. Stats
        st.write(f"**–ù–∞–π–¥–µ–Ω–æ —Å–≤–µ—á–µ–π:** {len(candles)}")
        
        # 3. Segments Table
        if segments:
            # Display Segments Table
            seg_data = []
            for i, s in enumerate(segments): # Changed parsed_batch to segments
                meta = s['META']
                stats = s['CONTEXT']['STATS']
                imp = s['IMPULSE']
                
                row = {
                    "Symbol": meta.get('symbol', 'Unknown'), # Changed raw_symbol to symbol
                    "TF": meta.get('tf', 'Unknown'),
                    "Direction": imp.get('y_dir'), # "UP" / "DOWN"
                    "Strength": imp.get('y_size'), # "Weak" / "Medium" / "Strong"
                    "Candles": stats.get('candles_count'),
                    "Vol (M)": f"{stats.get('sum_volume', 0)/1_000_000:.2f}M",
                    "Liq Ratio": stats.get('liq_dominance_ratio')
                }
                seg_data.append(row)
            
            # Display Table
            if seg_data:
                st.dataframe(pd.DataFrame(seg_data), use_container_width=True)
            
            # Save Button (Only if segments exist)
            with col_lab_save:
                # Transactional Save
                if st.button(f"üíæ –ó–∞–≥—Ä—É–∑–∏—Ç—å {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ –ë–î", type="primary"):
                    with st.spinner("–¢–æ—Ç–∞–ª—å–Ω–∞—è –∑–∞–ø–∏—Å—å (–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è)..."):
                        try:
                            s_count, c_count = batch_parser.save_batch_transactionally(supabase, segments, candles)
                            with col_lab_status:
                                st.success(f"‚úÖ –£–°–ü–ï–•! –ó–∞–ø–∏—Å–∞–Ω–æ: {s_count} —Å–µ–≥–º–µ–Ω—Ç–æ–≤, {c_count} —Å–≤–µ—á–µ–π.")
                            st.balloons()
                            # Clear state
                            st.session_state['lab_checked'] = False
                            st.session_state['lab_segments'] = []
                        except Exception as e:
                            st.error(f"‚ùå –û–®–ò–ë–ö–ê –ó–ê–ü–ò–°–ò: {e}")
                            st.error("–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞. –î–∞–Ω–Ω—ã–µ –æ—Ç–∫–∞—Ç–∏–ª–∏—Å—å (Rollback). –ë–∞–∑–∞ —á–∏—Å—Ç–∞.")
        else:
            st.info("–í–∞–ª–∏–¥–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
